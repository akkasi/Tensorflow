{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here a CNN with 3 different conv layers  is implemented. Each conv layer is followed by a maxpool layer. At the end two different fully connected layers are also considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from util.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Parameters -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 32, 32, 1)\n",
      "(4000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "Sample_number=10000\n",
    "Feature_Number=1024\n",
    "batch_size=256\n",
    "learning_rate=0.01\n",
    "display_step=20\n",
    "epochs=100\n",
    "DataObj=Data(data_len=Feature_Number,Sample_Number=Sample_number,Test_percentage=40)\n",
    "Train_x,Train_y,Test_x,Test_y=DataObj.CNN_data()\n",
    "Number_of_batches=int(len(Train_x)/batch_size)\n",
    "\n",
    "Train_x=Train_x.reshape([-1,32,32,1]) # 32*32 =1024\n",
    "Test_x=Test_x.reshape([-1,32,32,1])\n",
    "\n",
    "print (Train_x.shape)\n",
    "print (Test_x.shape)\n",
    "\n",
    "X=tf.placeholder(\"float\",[None,32,32,1])\n",
    "Y=tf.placeholder(\"float\",[None,10])\n",
    "\n",
    "p_keep_conv = tf.placeholder(\"float\")\n",
    "p_keep_FC = tf.placeholder(\"float\")\n",
    "\n",
    "Parameters={'Wc1':tf.Variable(tf.random_normal([2,2,1,32],stddev=0.01)),\n",
    "           'Wc2':tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01)),\n",
    "           'Wc3':tf.Variable(tf.random_normal([4,4,64,128],stddev=0.01)),\n",
    "           'WF1':tf.Variable(tf.random_normal([4*4*128,700],stddev=0.01)),\n",
    "           'WF2':tf.Variable(tf.random_normal([700,800],stddev=0.01)),\n",
    "           'Out':tf.Variable(tf.random_normal([800,10],stddev=0.01)),\n",
    "           'bc1':tf.Variable(tf.zeros([32])),\n",
    "           'bc2':tf.Variable(tf.zeros([64])),\n",
    "           'bc3':tf.Variable(tf.zeros([128])),\n",
    "           'bF1':tf.Variable(tf.zeros([700])),\n",
    "           'bF2':tf.Variable(tf.zeros([800])),\n",
    "           'bO':tf.Variable(tf.zeros([10]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph definition---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(Input,Weights):\n",
    "    \n",
    "    conv1=tf.nn.conv2d(Input,Weights['Wc1'],strides=[1,1,1,1],padding='SAME')\n",
    "    conv1=tf.nn.bias_add(conv1,Weights['bc1'])\n",
    "    conv1=tf.nn.relu(conv1) # conv1 shape=[-1,32,32,32]\n",
    "    Mpl1=tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    Mpl1=tf.nn.dropout(Mpl1,p_keep_conv) # Mpl1 shape= [-1,16,16,32]\n",
    "    \n",
    "    conv2=tf.nn.conv2d(Mpl1,Weights['Wc2'],strides=[1,1,1,1],padding='SAME')\n",
    "    conv2=tf.nn.bias_add(conv2,Weights['bc2'])\n",
    "    conv2=tf.nn.relu(conv2) # conv2 shape=[-1,16,16,64]\n",
    "    Mpl2=tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    Mpl2=tf.nn.dropout(Mpl2,p_keep_conv) #[Mpl2 shape=[-1,8,8,64]]\n",
    "    \n",
    "    conv3=tf.nn.conv2d(Mpl2,Weights['Wc3'],strides=[1,1,1,1],padding='SAME')\n",
    "    conv3=tf.nn.bias_add(conv3,Weights['bc3'])\n",
    "    conv3=tf.nn.relu(conv3)    # conv3 shape=[-1,8,8,128]\n",
    "    Mpl3=tf.nn.max_pool(conv3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    Mpl3=tf.nn.dropout(Mpl3,p_keep_conv) # Mpl3 shape=[-1,4,4,128]\n",
    "    \n",
    "    # below section is important \n",
    "    InF1=tf.reshape(Mpl3,[-1,Weights['WF1'].get_shape().as_list()[0]])\n",
    "    InF1=tf.nn.dropout(InF1,p_keep_FC)\n",
    "    \n",
    "    FC1=tf.nn.relu(tf.add(tf.matmul(InF1,Weights['WF1']),Weights['bF1']))\n",
    "    \n",
    "    \n",
    "    InF2=tf.nn.dropout(FC1,p_keep_FC)\n",
    "    FC2=tf.nn.relu(tf.add(tf.matmul(InF2,Weights['WF2']),Weights['bF2']))\n",
    "    \n",
    "    InOut=tf.nn.dropout(FC2,p_keep_FC)\n",
    "    \n",
    "    Out=tf.nn.relu(tf.add(tf.matmul(InOut,Weights['Out']),Weights['bO']))\n",
    "    \n",
    "    \n",
    "    return tf.nn.softmax(Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction_prob=model(X,Parameters)\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Prediction_prob,labels=Y))\n",
    "\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "True_Predictions=tf.equal(tf.argmax(Prediction_prob,1),tf.argmax(Y,1))\n",
    "\n",
    "Accuracy=tf.reduce_mean(tf.cast(True_Predictions,'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph runinng ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        avg_cost=0\n",
    "        for j in range(Number_of_batches):\n",
    "            Trx,Try=next_batch(batch_size, Train_x,Train_y)\n",
    "            sess.run(train_step,feed_dict={X:Trx,Y:Try,p_keep_conv:0.8,p_keep_FC:0.8})\n",
    "            avg_cost+=sess.run(cost,feed_dict={X:Trx,Y:Try,p_keep_conv:1.,p_keep_FC:1.})/Number_of_batches\n",
    "        if i%display_step==0:\n",
    "            Train_Accuracy=sess.run(Accuracy,feed_dict={X:Trx,Y:Try,p_keep_conv:1.,p_keep_FC:1.})\n",
    "            Test_Accuracy=sess.run(Accuracy,feed_dict={X:Test_x,Y:Test_y,p_keep_conv:1.,p_keep_FC:1.})\n",
    "            print (\"Epoch: %03d/%03d cost: %.9f train_acc: %.3f test_acc: %.3f\" \n",
    "                   % (i, epochs, avg_cost, Train_Accuracy, Test_Accuracy))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
