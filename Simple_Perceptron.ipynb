{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from util.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple FeedForward-Back Propagation NN is going to be implemented here. We are using toy data instead of using mnist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data and Parameters ---------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sample_number=10000\n",
    "Feature_Number=1024\n",
    "batch_size=256\n",
    "learning_rate=0.01\n",
    "display_step=50\n",
    "units_h=700 # number of units in hidden layer\n",
    "units_o=10 # number of units in output layer which equals to the number of classes\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataObj=Data(data_len=Feature_Number,Sample_Number=Sample_number,Test_percentage=40)\n",
    "Train_x,Train_y,Test_x,Test_y=DataObj.CNN_data()\n",
    "Number_of_batches=int(len(Train_x)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### structure definition ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(dtype=tf.float32,shape=[None,Feature_Number])\n",
    "Y=tf.placeholder(dtype=tf.float32,shape=[None,10])\n",
    "\n",
    "W_h=tf.Variable(tf.random_normal([Feature_Number,units_h],stddev=0.01))\n",
    "b_h=tf.Variable(tf.random_normal([units_h]))\n",
    "\n",
    "W_o=tf.Variable(tf.random_normal([units_h,units_o],stddev=0.01))\n",
    "b_o=tf.Variable(tf.random_normal([units_o]))\n",
    "\n",
    "\n",
    "def model(X,W_h,b_h,W_o,b_o):\n",
    "    h=tf.nn.relu(tf.matmul(X,W_h)+b_h)\n",
    "    o=tf.nn.sigmoid(tf.matmul(h,W_o)+b_o)\n",
    "    result=tf.nn.softmax(o) # Note that since we are going to use softmax_cross_entropy_with_logits\n",
    "    #in our cost function so, its not necesary to use the softmax here. It will not affect the cost function\n",
    "    return result\n",
    "\n",
    "Prediction=model(X,W_h,b_h,W_o,b_o)\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Prediction,labels=Y))\n",
    "\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "predicted_label=tf.equal(tf.argmax(Prediction, 1), tf.argmax(Y, 1)) \n",
    "Accuracy=tf.reduce_mean(tf.cast(predicted_label, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epochs):\n",
    "        avg_cost=0\n",
    "        for j in range(Number_of_batches):\n",
    "            Trx,Try=next_batch(batch_size, Train_x,Train_y)\n",
    "            sess.run(train_step,feed_dict={X:Trx,Y:Try})\n",
    "            avg_cost+=sess.run(cost,feed_dict={X:Trx,Y:Try})/Number_of_batches\n",
    "        if i% display_step==0:\n",
    "            Train_Accuracy=sess.run(Accuracy,feed_dict={X:Train_x,Y:Train_y})\n",
    "            Test_Accuracy=sess.run(Accuracy,feed_dict={X:Test_x,Y:Test_y})\n",
    "            \n",
    "            print(\"Epoch: %03d/%03d cost: %.9f Train_Acc: %.3f\"\n",
    "                 %(i,epochs,avg_cost,Train_Accuracy,Test_Accuracy))\n",
    "sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
